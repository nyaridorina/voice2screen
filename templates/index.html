<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Voice Transcription</title>
    <style>
        body {
            background-color: green; /* Set background color to green */
            color: white; /* Set text color to white */
            font-family: Arial, sans-serif; /* Optional: Set a clear font */
            text-align: center; /* Center the text */
            margin-top: 20%; /* Adjust positioning */
        }
    </style>
</head>
<body>
    <p id="transcription">Waiting for voice input...</p>

    <script>
        // Your existing JavaScript for voice detection and transcription remains unchanged
        let mediaRecorder;
        let audioChunks = [];
        let audioContext;
        let analyser;
        let microphone;
        let silenceTimeout;

        // Voice Activity Detection and Audio Capture
        async function startListening() {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioContext = new AudioContext();
            analyser = audioContext.createAnalyser();
            microphone = audioContext.createMediaStreamSource(stream);
            microphone.connect(analyser);

            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = function(event) {
                audioChunks.push(event.data);
                if (mediaRecorder.state === "inactive") {
                    sendAudioToServer(audioChunks);
                }
            };

            detectVoice();
        }

        function detectVoice() {
            const bufferLength = analyser.fftSize;
            const dataArray = new Uint8Array(bufferLength);

            function analyzeAudio() {
                analyser.getByteTimeDomainData(dataArray);
                const maxVolume = Math.max(...dataArray);

                // If volume is above a certain threshold, start recording
                if (maxVolume > 130) { // Adjust threshold based on sensitivity
                    console.log("Voice detected. Recording...");
                    if (mediaRecorder.state === "inactive") {
                        audioChunks = [];
                        mediaRecorder.start();
                    }
                    // If voice detected, reset silence timeout
                    clearTimeout(silenceTimeout);
                    silenceTimeout = setTimeout(stopRecording, 2000); // Stop recording after 2 seconds of silence
                }
                requestAnimationFrame(analyzeAudio);
            }

            analyzeAudio();
        }

        function stopRecording() {
            console.log("Stopping recording due to silence.");
            if (mediaRecorder.state === "recording") {
                mediaRecorder.stop();
            }
        }

        function sendAudioToServer(chunks) {
            const blob = new Blob(chunks, { type: 'audio/wav; codecs=opus' });
            const formData = new FormData();
            formData.append('file', blob, 'audio.wav');

            fetch('/transcribe', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                document.getElementById('transcription').textContent = data.text;
            })
            .catch(error => {
                console.error('Error:', error);
            });
        }

        // Start listening for voice input on page load
        window.onload = startListening;
    </script>
</body>
</html>
